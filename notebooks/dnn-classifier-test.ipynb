{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test script for using ParameterizedDNNClassifier with SKL GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a library for quickly creating deep neural network (DNN) models out of standard layer types, activation functions, and other components without hand-crafting Theano or other low level code.  Keras has the additional advantage that its models can be run with Theano and TensorFlow backends without modification (usually, unless you're writing your own Keras extensions).  \n",
    "\n",
    "Since one of the most common tasks I do with ML tools is supervised multiclass classification, I wanted an easy way to include a DNN for such classifiers whenever I'm screening models in scikit-learn.  ParameterizedDNNClassifier takes some simple parameters and the generates an appropriate multilayer DNN in Keras, with one or more fully-connected hidden layers (with specifiable activation function, defaulting to ReLU), and configurable input and output layers.  Future additions will make the optimizer and other aspects parameterized as well.  \n",
    "\n",
    "ParameterizedDNNClassifier subclasses BaseEstimator and ClassifierMixin from scikit-learn, and provides appropriate score and predict functions which allow it to act like any other SKL estimator.  With one exception (getting training history from the underlying Keras object), you can use ParameterizedDNNClassifier in a Pipeline or in GridSearchCV, etc.  \n",
    "\n",
    "The following test harness does a simple grid search cross validation over a synthetic classification data set with 10K data points and 10 classes.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import sys\n",
    "import pprint as pp\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn_mmadsen import ParameterizedDNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Seaborn confusion matrix heatmap\n",
    "def confusion_heatmap(y_test, y_pred, labels):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    mat = confusion_matrix(y_test, y_pred)\n",
    "    ax = sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                     xticklabels=labels, yticklabels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Replication #######\n",
    "\n",
    "#random.seed(7112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_x = pd.read_csv(\"../testdata/classification-10k-10classes-x.csv.gz\")\n",
    "df_y = pd.read_csv(\"../testdata/classification-10k-10classes-y.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############ prepare data ###########\n",
    "\n",
    "# specify the correct data types because we're probably using the GPU\n",
    "X = df_x.astype(np.float32)\n",
    "y = df_y.astype(np.int32)\n",
    "\n",
    "# one-hot encode the class label since the output layer of the DNN will have multiple units, \n",
    "# each corresponding to a class\n",
    "y = pd.concat([y, pd.get_dummies(y['0']).rename(columns=lambda x: 'col_' + str(x))], axis=1)\n",
    "y.drop('0', axis=1, inplace=True\t)\n",
    "\n",
    "# get pure numpy arrays\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "### create a train/test split ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "x_train_rows = X_train.shape[0]\n",
    "x_train_cols = X_train.shape[1]\n",
    "x_test_rows = X_test.shape[0]\n",
    "x_test_cols = X_test.shape[1]\n",
    "\n",
    "# make sure the data arrays are the correct shape, or Theano will never let you hear the end of it...\n",
    "X_train = X_train.reshape(x_train_rows, x_train_cols)\n",
    "X_test = X_test.reshape(x_test_rows, x_test_cols)\n",
    "\n",
    "print \"Prepared data sets\"\n",
    "print \"Train:\"\n",
    "print \"X_train: \", X_train.shape\n",
    "print \"y_train: \", y_train.shape\n",
    "print \"\\nTest:\"\n",
    "print \"X_test: \",X_test.shape\n",
    "print \"y_test: \",y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "\t'clf__dropout_fraction': [0.9, 0.5],\n",
    "\t'clf__sgd_lr': [0.01, 0.1],\n",
    "}\n",
    "\n",
    "est = ParameterizedDNNClassifier(input_dimension=20,\n",
    "        output_dimension=10,\n",
    "\t\tnum_dense_hidden=2,\n",
    "\t\tepochs=2,\n",
    "\t\thidden_sizes=[1000,2000,1000])\n",
    "\n",
    "grid_search = GridSearchCV(est, params, n_jobs = 1, verbose = 1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# This is Keras-specific code.  The fitted model stores the history of training \n",
    "# and validation accuracy so we can examine over or underfitting.  It is also \n",
    "# useful for retrieving the actual number of training epochs in the case that\n",
    "# we have early stopping activated.\n",
    "\n",
    "history = grid_search.best_estimator_.get_history()\n",
    "actual_epoch_count = len(history['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"============= Best Estimator from GridSearchCV ==============\"\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters:\")\n",
    "best_params = grid_search.best_estimator_.get_params()\n",
    "for param in sorted(best_params.keys()):\n",
    "    print(\"param: %s: %r\" % (param, best_params[param]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"============== Evaluation on Holdout Test Set =============\"\n",
    "\n",
    "predictions = grid_search.predict(X_test)\n",
    "actuals = np.argmax(y_test, axis=1)\n",
    "\n",
    "print \"accuracy on test: %s\" % accuracy_score(actuals, predictions)\n",
    "\n",
    "print(classification_report(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a graph of the training/validation accuracy versus training epoch\n",
    "# to look for overfitting\n",
    "\n",
    "train_acc_hist = history['acc']\n",
    "val_acc_hist = history['val_acc']\n",
    "epoch_list = range(0, actual_epoch_count)\n",
    "\n",
    "dat = { 'train_acc': train_acc_hist, 'val_acc': val_acc_hist }\n",
    "hist_df = pd.DataFrame(data=dat, index=epoch_list)\n",
    "\n",
    "plt.figure(figsize=(11,8.5), dpi=300)\n",
    "\n",
    "plt.plot(hist_df.index, hist_df['train_acc'], color='green', linestyle='dashed', marker='+',\n",
    "     markerfacecolor='black', markersize=7, label=\"Training Accuracy\", alpha=0.4)\n",
    "plt.plot(hist_df.index, hist_df['val_acc'], color='red', linestyle='dashed', marker='x',\n",
    "     markerfacecolor='black', markersize=7, label=\"Validation Accuracy\", alpha=0.4)\n",
    "plt.legend(fontsize='large')\n",
    "\n",
    "plt.xlabel('Epoch', fontsize='large')\n",
    "plt.ylabel('Classification Accuracy', fontsize='large')\n",
    "plt.title('Training and Validation Accuracy By Epoch', fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = range(0, x_train_cols)\n",
    "confusion_heatmap(actuals, predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
